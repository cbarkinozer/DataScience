{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are environment variables loaded correctly?  True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# **BURAYI .env DOSYANIZIN YERI OLACAK SEKILDE DEGISTIRIN***\n",
    "dotenv_path = 'key.env'\n",
    "is_loaded = load_dotenv(dotenv_path)\n",
    "\n",
    "# Load config values\n",
    "\n",
    "# Setting up the deployment name\n",
    "chatgpt_model_name = os.getenv('CHATGPT_MODEL')\n",
    "\n",
    "# This is set to `azure`\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai.api_base = os.getenv('OPENAI_API_BASE')\n",
    "\n",
    "# Currently Chat Completions API have the following versions available: 2023-03-15-preview\n",
    "openai.api_version = os.getenv('OPENAI_API_VERSION')\n",
    "\n",
    "deployment_name = os.getenv('DEPLOYMENT_NAME')\n",
    "\n",
    "\n",
    "print(\"Are environment variables loaded correctly? \", is_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"docs\\MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"docs\\MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"docs\\MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"docs\\MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cbark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embedding = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\"\n",
    "\n",
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005847679808422499"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.dot(embedding1, embedding2)\n",
    "np.dot(embedding1, embedding3)\n",
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Invalid switch - \"docs\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n"
     ]
    }
   ],
   "source": [
    "#! pip install chromadb\n",
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = 'docs/chroma/'\n",
    "!del -rf ./docs/chroma  # remove old database files if any (change del to rm in linux)\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is there an email i can ask for help\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "len(docs)\n",
    "docs[0].page_content\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"So later this quarter, we'll use the discussion sections to talk about things like convex \\noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \\nlearning algorithm for modeling time series and a few other things, so  extensions to the \\nmaterials that I'll be covering in the main  lectures. And attend ance at the discussion \\nsections is optional, okay?  \\nSo that was all I had from l ogistics. Before we move on to start talking a bit about \\nmachine learning, let me check what questions you have. Yeah?  \\nStudent : [Inaudible] R or something like that?  \\nInstructor (Andrew Ng) : Oh, yeah, let's see, right. So our policy has been that you're \\nwelcome to use R, but I would strongly advi se against it, mainly because in the last \\nproblem set, we actually supply some code th at will run in Octave  but that would be \\nsomewhat painful for you to translate into R yourself. So for your other assignments, if \\nyou wanna submit a solution in R, that's fi ne. But I think MATLAB is actually totally \\nworth learning. I know R and MATLAB, and I personally end up using MATLAB quite a \\nbit more often for various reasons. Yeah?  \\nStudent : For the [inaudible] pr oject [inaudible]?  \\nInstructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \\ngroups of three, or you're welcome to do it by yo urself or in groups of two. Grading is the \\nsame regardless of the group size, so with  a larger group, you probably — I recommend\", metadata={'page': 9, 'source': 'docs\\\\MachineLearning-Lecture01.pdf'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "docs = vectordb.similarity_search(question,k=5)\n",
    "\n",
    "docs[0]\n",
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 2, 'source': 'docs\\\\MachineLearning-Lecture02.pdf'}\n",
      "{'page': 2, 'source': 'docs\\\\MachineLearning-Lecture02.pdf'}\n",
      "{'page': 0, 'source': 'docs\\\\MachineLearning-Lecture03.pdf'}\n",
      "{'page': 0, 'source': 'docs\\\\MachineLearning-Lecture03.pdf'}\n",
      "{'page': 7, 'source': 'docs\\\\MachineLearning-Lecture03.pdf'}\n",
      "other is, I don’t know, I can also mumble about ju stifications, such as things to the central \n",
      "limit theorem. It turns out that if you, for th e vast majority of problems, if you apply a \n",
      "linear regression model like this and try to m easure the distribution of the errors, not all \n",
      "the time, but very often you find that the erro rs really are Gaussian. That this Gaussian \n",
      "model is a good assumption for the error in regression proble ms like these. Some of you \n",
      "may have heard of the central limit theo rem, which says that the sum of many \n",
      "independent random variables will tend towards a Gaussian. So if the error is caused by many effects, like the mood of th e seller, the mood of the buyer,  some other features that \n",
      "we miss, whether the place has a garden or not, and if all of these e ffects are independent, \n",
      "then by the central limit theorem you might be inclined to believe that the sum of all \n",
      "these effects will be approximately Gaussian. If  in practice, I guess, the two real answers \n",
      "are that, 1.) In practice this is actually a reasonably accurate assumption, and 2.) Is it \n",
      "turns out to be mathematically c onvenient to do so. Okay? Yeah?  \n",
      "Student: It seems like we’re saying if we assu me that area around model has zero mean, \n",
      "then the area is centered ar ound our model. Which it seems al most like we’re trying to \n",
      "assume what we’re trying to prove. Instructor? \n",
      "That’s the [inaudible] but, yes. You are assu ming that the error has zero mean. Which is,\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about regression in the third lecture?\"\n",
    "docs = vectordb.similarity_search(question,k=5)\n",
    "\n",
    "for doc in docs:\n",
    "    print(doc.metadata)\n",
    "\n",
    "print(docs[4].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
