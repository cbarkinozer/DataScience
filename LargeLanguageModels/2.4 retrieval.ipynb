{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are environment variables loaded correctly?  True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# **BURAYI .env DOSYANIZIN YERI OLACAK SEKILDE DEGISTIRIN***\n",
    "dotenv_path = 'key.env'\n",
    "is_loaded = load_dotenv(dotenv_path)\n",
    "\n",
    "# Load config values\n",
    "\n",
    "# Setting up the deployment name\n",
    "chatgpt_model_name = os.getenv('CHATGPT_MODEL')\n",
    "\n",
    "# This is set to `azure`\n",
    "openai.api_type = \"azure\"\n",
    "\n",
    "# The API key for your Azure OpenAI resource.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# The base URL for your Azure OpenAI resource. e.g. \"https://<your resource name>.openai.azure.com\"\n",
    "openai.api_base = os.getenv('OPENAI_API_BASE')\n",
    "\n",
    "# Currently Chat Completions API have the following versions available: 2023-03-15-preview\n",
    "openai.api_version = os.getenv('OPENAI_API_VERSION')\n",
    "\n",
    "deployment_name = os.getenv('DEPLOYMENT_NAME')\n",
    "\n",
    "\n",
    "print(\"Are environment variables loaded correctly? \", is_loaded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cbark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n"
     ]
    }
   ],
   "source": [
    "#! pip install lark\n",
    "\n",
    "# Similarity Search\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "persist_directory = 'docs/chroma/'\n",
    "\n",
    "embedding = HuggingFaceEmbeddings()\n",
    "\n",
    "vectordb = Chroma(\n",
    "\n",
    "    persist_directory=persist_directory,\n",
    "\n",
    "    embedding_function=embedding\n",
    "\n",
    ")\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.', metadata={}),\n",
       " Document(page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.', metadata={})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "\n",
    "]\n",
    "smalldb = Chroma.from_texts(texts, embedding=embedding)\n",
    "\n",
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\"\n",
    "\n",
    "smalldb.similarity_search(question, k=2)\n",
    "\n",
    "smalldb.max_marginal_relevance_search(question,k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So later this quarter, we'll use the discussion sections to talk about things like convex \\noptimizat\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "\n",
    "docs_ss = vectordb.similarity_search(question,k=3)\n",
    "\n",
    "docs_ss[0].page_content[:100]\n",
    "\n",
    "docs_ss[1].page_content[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'those homeworks will be done in either MATLA B or in Octave, which is sort of â€” I \\nknow some people '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)\n",
    "\n",
    "docs_mmr[0].page_content[:100]\n",
    "\n",
    "docs_mmr[1].page_content[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\"\n",
    "\n",
    "docs = vectordb.similarity_search(\n",
    "\n",
    "    question,\n",
    "\n",
    "    k=3,\n",
    "\n",
    "    filter={\"source\":\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\"}\n",
    "\n",
    ")\n",
    "\n",
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import AzureOpenAI\n",
    "\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "metadata_field_info = [\n",
    "\n",
    "    AttributeInfo(\n",
    "\n",
    "        name=\"source\",\n",
    "\n",
    "        description=\"The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n",
    "\n",
    "        type=\"string\",\n",
    "\n",
    "    ),\n",
    "\n",
    "    AttributeInfo(\n",
    "\n",
    "        name=\"page\",\n",
    "\n",
    "        description=\"The page from the lecture\",\n",
    "\n",
    "        type=\"integer\",\n",
    "\n",
    "    ),\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Lecture notes\"\n",
    "\n",
    "llm = AzureOpenAI(deployment_name=\"text-davinci-003\" , model_name=\"text-davinci-003\" , temperature=0)\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "\n",
    "    llm,\n",
    "\n",
    "    vectordb,\n",
    "\n",
    "    document_content_description,\n",
    "\n",
    "    metadata_field_info,\n",
    "\n",
    "    verbose=True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query='regression' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='source', value='docs/cs229_lectures/MachineLearning-Lecture03.pdf') limit=None\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about regression in the third lecture?\"\n",
    "\n",
    "# You will receive a warning about predict_and_parse being deprecated the first time you executing the next line. This can be safely ignored.\n",
    "\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "for d in docs:\n",
    "    \n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap our vectorstore\n",
    "\n",
    "llm = AzureOpenAI(deployment_name=\"text-davinci-003\" , model_name=\"text-davinci-003\", temperature=0)\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "\n",
    "    base_compressor=compressor,\n",
    "\n",
    "    base_retriever=vectordb.as_retriever()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "\"I personally end up using MATLAB quite a bit more often for various reasons.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "\"I personally end up using MATLAB quite a bit more often for various reasons.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "\"I personally end up using MATLAB quite a bit more often for various reasons.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "\"I personally end up using MATLAB quite a bit more often for various reasons.\"\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "\n",
    "pretty_print_docs(compressed_docs)\n",
    "\n",
    "# Combining various techniques\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "\n",
    "    base_compressor=compressor,\n",
    "\n",
    "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "\"I personally end up using MATLAB quite a bit more often for various reasons.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "\"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "\"So one more organizational question. I'm curious, how many of you know MATLAB? Wow, cool, quite a lot. Okay. So as part of the â€” actually how many of you know Octave or have used Octave ? Oh, okay, much smaller number.\"\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "\n",
    "loader = PyPDFLoader(\"docs\\MachineLearning-Lecture01.pdf\")\n",
    "\n",
    "pages = loader.load()\n",
    "\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "\n",
    "joined_page_text=\" \".join(all_page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "\n",
    "splits = text_splitter.split_text(joined_page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cbark\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Saxena and Min Sun here did, wh ich is given an image like this, right? This is actually a \\npicture taken of the Stanford campus. You can apply that sort of cl ustering algorithm and \\ngroup the picture into regions. Let me actually blow that up so that you can see it more \\nclearly. Okay. So in the middle, you see the lines sort of groupi ng the image together, \\ngrouping the image into [inaudible] regions.  \\nAnd what Ashutosh and Min did was they then  applied the learning algorithm to say can \\nwe take this clustering and us e it to build a 3D model of the world? And so using the \\nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \\nworld looks like so that they could come up with a 3D model that you can sort of fly \\nthrough, okay? Although many people used to th ink it's not possible to take a single \\nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \\nalgorithm is the first step. They were able to.  \\nI'll just show you one more example. I like this  because it's a picture of Stanford with our \\nbeautiful Stanford campus. So again, taking th e same sort of clustering algorithms, taking \\nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \\nregions. And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  You can sort of walk  into the ceiling, look\", metadata={})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve\n",
    "\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
    "\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)\n",
    "\n",
    "question = \"What are major topics for this class?\"\n",
    "\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "\n",
    "docs_svm[0]\n",
    "\n",
    "question = \"what did they say about matlab?\"\n",
    "\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "\n",
    "docs_tfidf[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
