{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#I learned a lot and implemented from the bottom notebooks\n#https://www.kaggle.com/startupsci/titanic-data-science-solutions\n#https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\n#Do not forget to visit them ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\n%matplotlib inline\nimport matplotlib.pyplot as plt  # Matlab stilinde grafik çizmek için\nimport seaborn as sns\ncolor = sns.color_palette()\nsns.set_style('darkgrid')\nimport warnings\ndef ignore_warn(*args, **kwargs):\n    pass\nwarnings.warn = ignore_warn #Sklearn ve seaborn'un verdiği cansıkıcı uyarıları engellemek için\n\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew #for some statistics\nfrom sklearn.preprocessing import LabelEncoder\n\npd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) #Float çıktıları 3 basamakla sınırlandırmak için",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Dosyaları yükle\n#Train tüm verilerimiz. Test ise belli bir kısmı\ntrain = pd.read_csv('../input/titanic/train.csv')\ntest = pd.read_csv('../input/titanic/test.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#ilk 5 elemanı göster\ntrain.head(5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#İlk 5 elemanı göster\ntest.head(5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#boyutlarına bak\ntrain.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#boyutlarına bak\ntest.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#'Id' sütununu kaydet\ntrain_ID = train['PassengerId']\ntest_ID = test['PassengerId']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#'Id' sütunu gereksiz bu yüzden sil\ntrain.drop(\"PassengerId\", axis = 1, inplace = True)\ntest.drop(\"PassengerId\", axis = 1, inplace = True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#silme başarılı\ntrain.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#silme başarılı\ntest.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Data Processing\n#Aykırı değerler",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Özellik mühendisliği\n\n# Train ve test verilerini aynı dataframe içerisine birleştiriyoruz\nntrain = train.shape[0]\nntest = test.shape[0]\n\ny_train = train.Survived.values\n#birleştirme işlemi\nall_data = pd.concat((train, test)).reset_index(drop=True)\n#'Survived' sütununu siliyoruz\nall_data.drop(['Survived'], axis=1, inplace=True)\n\n#Tüm datanın büyüklüğü\nprint(\"all_data büyüklüğü : {}\".format(all_data.shape))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Eksik veriler\n#Tüm veriye oranla eksiklik yüzdesi veriyoruz\nall_data_na = (all_data.isnull().sum() / len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n#Eksik veriler adında bir tablo oluşturuyoruz\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\n#İlk 20 satıra bakıyoruz\nmissing_data.head(20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Eksik veriyi tabloda gösteriyoruz\nf, ax = plt.subplots(figsize=(15, 12))\nplt.xticks(rotation='90')\nsns.barplot(x=all_data_na.index, y=all_data_na)\nplt.xlabel('Özellikler', fontsize=15)\nplt.ylabel('Eksik değer oranı', fontsize=15)\nplt.title('Özellik başına eksik veri oranı', fontsize=15)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#İlginçtir ki burda sınıfla güçlü bir ilişki bekliyordum ancak öyle çıkmadı. Bunun sebebinin sınıflardaki kişi\n#sayısı farkı ile ilgili olabileceğini düşünüyorum. Bilete ödenen ücretle hayatta kalmanın güçlü ilişkisi bunu doğrular\n#nitelikte.\n#Veri korelasyonu\ncorrmat = train.corr()\nplt.subplots(figsize=(12,9))\nsns.heatmap(corrmat, vmax=0.9, square=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Ölen ve yaşayanların yaş ile ilişkilerine bakıyorum\ng = sns.FacetGrid(train, col='Survived')\ng.map(plt.hist, 'Age', bins=20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Sınıf ile hayatta kalma durumları ilişkisi\n# grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\ngrid = sns.FacetGrid(train, col='Survived', row='Pclass', size=2.2, aspect=1.6)\ngrid.map(plt.hist, 'Age', alpha=.5, bins=20)\ngrid.add_legend();",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "all_data['Name'] = all_data['Name'].map(lambda x: re.sub('\\W', '', x))\nall_data['Name'] = all_data['Name'].map(lambda x: re.sub('\\W', '', x))\nall_data['Name'] = all_data['Name'].map(lambda x: re.sub('\\W', '', x))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Korelasyondan 'Parch' ile 'SibSp' sayısının aynı şeyi gösterdiğini anlıyoruz. Mantık olarak düşününce de bunu kanıtlar nitelikte\n#Bu nedenle bir tanesini sileceğim\nall_data = all_data.drop(['Parch'], axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Fare(Bilet parası): %0.076'lık çok az eksik veri söz konusu, bilet parasının da sınıfa bağımlı bir değişken \n#olduğunu bildiğimiz için o sınıftaki bilet ücretlerinin medyanını atıyoruz.\nall_data[\"Fare\"] = all_data.groupby(\"Pclass\")[\"Fare\"].transform(lambda x: x.fillna(x.median()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Cabin: Çok büyük kısmının(%77.4) eksik veri olması ve kabin numarasının bir fayda sağlamayacağı kanısı ile silmeye karar veriyorum.\nall_data = all_data.drop(['Cabin'], axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Age: Büyük kısmı eksik(%20).Burası en önemli karar noktalarından biri. Emin olmamakla beraber sınıfın yaş medyanını atamaya karar veriyorum.\nall_data[\"Age\"] = all_data.groupby(\"Pclass\")[\"Age\"].transform(lambda x: x.fillna(x.median()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Embarked: Gemiye nereye bindikleri. Çok az değer eksiği var. Kendi sınıfında en sık görüleni atayacağım(Kategorik veri).\nall_data['Embarked'] = all_data['Embarked'].fillna(all_data['Embarked'].mode()[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Geriye kalan eksik değer var mı diye kontrol edilir\nall_data_na = (all_data.isnull().sum() / len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Embarked ve Sex değişkenini kategorikten sayısala dönüştüreceğiz.\nnumber = LabelEncoder()\nall_data[\"Sex\"]= number.fit_transform(all_data[\"Sex\"].astype('str'))\nall_data[\"Embarked\"]= number.fit_transform(all_data[\"Embarked\"].astype('str'))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Çarpık değerler\nnumeric_feats = all_data.dtypes[all_data.dtypes != \"object\"].index\n\n# Tüm sayısal değerlerdeki çarpıklığa bakıyoruz\nskewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nNumerical özelliklerdeki çarpıklık: \\n\")\nskewness = pd.DataFrame({'Skew' :skewed_feats})\nskewness.head(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#The more skewed the data, the less accurate model will be.\nfrom scipy.special import boxcox1p\nskewed_features = skewness.index\nlam = 0.15\nfor feat in skewed_features:\n    #all_data[feat] += 1\n    all_data[feat] = boxcox1p(all_data[feat], lam)\n\n#Sahte kategorik verileri alıyoruz\nall_data = pd.get_dummies(all_data)\nprint(all_data.shape)\n#Yeni train ve test kümelerini alıyoruz\ntrain = all_data[:ntrain]\ntest = all_data[ntrain:]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Modelleme\n#Kütüphaneleri ekliyoruz\nfrom sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC # lineer modellerimiz\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.model_selection import KFold, cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error #Modellerin başarısını ölçmek için\nimport xgboost as xgb # Son zamanlarda yüksek başarı gösteren bir model\nimport lightgbm as lgb ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Define a cross validation strategy\n#cross_val_score fonksiyonunu Sklearn kütüphanesinden kullanıyoruz ama kendi içerisinde karıştırmayı\n# bulundurmuyor bu nedenle biz ayrıca manuel karıştırmayı sağlıyoruz\n#Doğrulama fonksiyonu\nn_folds = 5\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n    return(rmse)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Modellerin temelleri",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Lasso regresyon aykırı değerlere karşı hassas olduğu için o değerlere karşı güçlendireceğiz.\n#Bunu sklearn'ün Robustscaler() fonksiyonu ile yapacağız.\nlasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#ElasticNet regresyonu da aynı şekilde güçlendiriyoruz.\nENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Kernel Ridge Regresyonu:\nKRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Gradient Boosting Regresyon :\n#Aykırı değerlere karşı sağlam kılan huber kaybı ile birlikte.\nGBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#XGBoost: Ölçeklenebilir, Taşınabilir ve Dağıtılmış Degrade Artırıcı Kütüphane\" sağlamayı amaçlamaktadır\nmodel_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#LightGBM: LightGBM, Light Gradient Boosting Machine'in kısaltmasıdır, ilk olarak Microsoft tarafından geliştirilen\n#makine öğrenimi için ücretsiz ve açık kaynaklı dağıtılmış bir gradyan artırma çerçevesidir. \n#Karar ağacı algoritmalarına dayanır ve sıralama, sınıflandırma ve diğer makine öğrenimi görevleri için kullanılır.\nmodel_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n                               learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                             bagging_freq = 5, feature_fraction = 0.2319,\n                            feature_fraction_seed=9, bagging_seed=9,\n                            min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Model skorları\n#Temel modellerimizin  cross-validation rmsle(çapraz onaylama kök ortalamalar logaritmik karesi)\n# hata ölçme metoduna göre başarılarını ölçeceğiz\n#İşlem birkaç dakika alabilir\nscore = rmsle_cv(lasso)\nprint(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = rmsle_cv(ENet)\nprint(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = rmsle_cv(KRR)\nprint(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = rmsle_cv(GBoost)\nprint(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = rmsle_cv(model_xgb)\nprint(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n\nscore = rmsle_cv(model_lgb)\nprint(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))\n\nprint(\"Done\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Xgboost score: 0.3648 (0.0240)\n#LGBM score: 0.3658 (0.0234)\n#Lasso score: 0.3819 (0.0233)\n#ElasticNet score: 0.3807 (0.0228)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#En başarılı ilk 4 modeli alıp yığıcam\n#Modelleri istifleme\n#Veri biliminde aynı modeli defalarca kullanmak bir fayda sağlamazken\n#farklı modelleri bir araya getirmek başarı sağlayabilmektedir*\n#Basit yığıtlama yaklaşımı: Temel modellerin ortalamasını almak\n#Scikit-learn'ü kendi modelimizle genişletmek(inheritence(miraslama) ve encapsulation(kapsülleme) yapmak)\n#için yeni bir sınıf oluşturuyoruz\n\nclass AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    #constructor\n    def __init__(self, models):\n        self.models = models\n        \n    # Veriyi sığdırmak için orijinal modelin klonlarını oluşturuyoruz\n    def fit(self, X, y):\n        self.models_ = [clone(x) for x in self.models]\n        \n        # Klonlanmış modelleri eğitiyoruz\n        for model in self.models_:\n            model.fit(X, y)\n\n        return self\n    \n    #Klonlanmış modeller için tahmin yapıyoruz ve ortalamasını alıyoruz\n    def predict(self, X):\n        predictions = np.column_stack([\n            model.predict(X) for model in self.models_\n        ])\n        return np.mean(predictions, axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Sadece 4 modelin ortalamasını alacağız isteseydik daha da fazla alabilirdik.ENet, GBoost, KRR and lasso alacağız.\naveraged_models = AveragingModels(models = (model_xgb,model_lgb, lasso,ENet))\n\nscore = rmsle_cv(averaged_models)\nprint(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n    def __init__(self, base_models, meta_model, n_folds=5):\n        self.base_models = base_models\n        self.meta_model = meta_model\n        self.n_folds = n_folds\n   \n    # Orijinal modelin klonları üzerine veriyi ekliyoruz\n    def fit(self, X, y):\n        self.base_models_ = [list() for x in self.base_models]\n        self.meta_model_ = clone(self.meta_model)\n        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n        \n        #Klon modelleri eğit sonra klonlanmış meta modelleri eğitmek için gereken\n        #out-of-fold(katlama dışı kalan) tahminleri yarat \n        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n        for i, model in enumerate(self.base_models):\n            for train_index, holdout_index in kfold.split(X, y):\n                instance = clone(model)\n                self.base_models_[i].append(instance)\n                instance.fit(X[train_index], y[train_index])\n                y_pred = instance.predict(X[holdout_index])\n                out_of_fold_predictions[holdout_index, i] = y_pred\n                \n        # Klonlanmış modelleri out-of-fold tahminleri kullanarak yeni bir özellik olacak şekilde eğit\n        self.meta_model_.fit(out_of_fold_predictions, y)\n        return self\n   \n    #Test verilerindeki tüm temel modellerin tahminlerini yapın ve ortalama tahminleri meta-model tarafından yapılan \n    #tahminler için meta özellikler olarak kullanın\n    def predict(self, X):\n        meta_features = np.column_stack([\n            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n            for base_models in self.base_models_ ])\n        return self.meta_model_.predict(meta_features)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Her iki model yığıtlama modelini karşılaştırabilmek için aynı modelleri girdi olarak kullanacağız\n#İşlem birkaç dakika sürebilir\nstacked_averaged_models = StackingAveragedModels(base_models = (model_xgb, GBoost, model_lgb),\n                                                 meta_model = ENet)\n\nscore = rmsle_cv(stacked_averaged_models)\nprint(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n#stacked regressor:\nstacked_averaged_models.fit(train.values, y_train)\nstacked_train_pred = stacked_averaged_models.predict(train.values)\nstacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\nprint(rmsle(y_train, stacked_train_pred))\n\nmodel_xgb.fit(train, y_train)\nxgb_train_pred = model_xgb.predict(train)\nxgb_pred = np.expm1(model_xgb.predict(test))\nprint(rmsle(y_train, xgb_train_pred))\n\nmodel_lgb.fit(train, y_train)\nlgb_train_pred = model_lgb.predict(train)\nlgb_pred = np.expm1(model_lgb.predict(test.values))\nprint(rmsle(y_train, lgb_train_pred))\n\n'''RMSE on the entire Train data when averaging'''\n\nprint('RMSLE score on train data:')\nprint(rmsle(y_train,stacked_train_pred*0.70 +\n               xgb_train_pred*0.15 + lgb_train_pred*0.15 ))\nensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Sonuçların olduğu bir tablo yapıyoruz ve bitiriyoruz\nsub = pd.DataFrame()\nsub['PassengerId'] = test_ID\nsub['Survived'] = ensemble\nsub.to_csv('submission.csv',index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
