{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open('tur_mixed_2014_10K-sentences.txt','r',encoding='utf8')\n",
    "text=f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Failed to capture some special characters. I added replace code for them manually. \n",
    "import string\n",
    "clean_text = text.translate(str.maketrans('','', string.punctuation)).replace(\"’\",\"\").replace(\"”\",\"\").replace(\"»\",\"\").replace(\"“\",\"\").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\barkin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "my_stopwords=set(stopwords.words('turkish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=nltk.word_tokenize(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-stop words are added by append\n",
    "words=[]\n",
    "for token in tokens:\n",
    "    if token not in my_stopwords:\n",
    "        words.append(token)\n",
    "words=\" \".join(words) # Converts list to string to make it tokenizable        \n",
    "tokens=nltk.word_tokenize(words) # Tokenized because it is a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of words with their frequencies where threshold is 5\n",
    "from collections import Counter\n",
    "def token_counter(tokens):\n",
    "    counts=Counter(tokens)\n",
    "    return counts\n",
    "vocabulary=token_counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bir': 2806, 'olarak': 591, 'olan': 454, 'kadar': 387, 'sonra': 348, 'büyük': 254, 'var': 243, 'yeni': 242, 'göre': 240, 'ilk': 228, 'olduğunu': 224, 'son': 215, 'ancak': 205, 'olduğu': 200, 'iyi': 190, '‘': 187, 'tarafından': 184, 'değil': 177, 'iki': 177, 'önemli': 175, 'başkanı': 174, 'zaman': 173, 'yer': 173, 'türkiye': 165, 'devam': 163, 'ilgili': 161, 'yıl': 159, 'türk': 158, 'önce': 155, 'dedi': 153, 'aynı': 152, 'arasında': 149, 'bin': 149, 'oldu': 148, 'gün': 147, 'kendi': 147, 'içinde': 145, 'yüzde': 144, 'yapılan': 143, 'etti': 141, 'sadece': 136, 'eden': 133, 'genel': 133, 'yok': 131, 'karşı': 130, 'tek': 129, 'birlikte': 126, '2': 121, 'şekilde': 121, 'gelen': 120, '3': 119, 'bile': 117, 'fazla': 116, 'böyle': 115, 'ben': 115, 'söyledi': 113, 'yılında': 110, 'bütün': 109, 'ardından': 108, '1': 107, 'diğer': 106, 'eğitim': 106, 'geçen': 106, 'ortaya': 104, 'bunun': 103, 'ifade': 101, 'mi': 101, 'üzerine': 97, 'olacak': 96, 'türkiyenin': 94, 'devlet': 93, 'bunu': 93, 'eski': 93, 'olmak': 92, 'dünya': 91, 'yaptığı': 91, 'artık': 91, 'doğru': 91, 'bugün': 90, 'bulunan': 89, 'özel': 89, 'üzerinde': 88, 'sahip': 87, '5': 85, 'alan': 85, 'i̇stanbul': 84, 'yine': 84, 'bizim': 84, 'başka': 83, 'vardır': 83, '10': 81, 'ediyor': 81, 'belediye': 81, 'olur': 81, 'yerine': 80, 'ayrıca': 80, 'hiçbir': 80, 'üzere': 79, 'kabul': 79, 'kişi': 79, 'milyon': 78, 'olması': 78, 'iş': 78, 'uzun': 76, 'farklı': 76, 'milli': 75, 'yapan': 74, 'avrupa': 74, 'hizmet': 74, 'yüksek': 73, 'konusunda': 73, 'tam': 72, 'geldi': 72, 'söz': 71, 'günü': 70, 'birçok': 70, 'sosyal': 70, 'rağmen': 70, 'üç': 70, '4': 69, 'olsun': 69, 'etmek': 68, 'burada': 68, 'benim': 68, 'şimdi': 67, 'siyasi': 67, 'saat': 66, 'bilgi': 66, 'özellikle': 65, 'onun': 64, 'türkiyede': 63, 'teknik': 62, 'küçük': 62, 'fakat': 62, 'tarihi': 61, 'sağlık': 61, 'ikinci': 60, 'parti': 60, 'karar': 60, 'ülke': 60, 'tarihinde': 59, 'hakkında': 59, 'adı': 59, 'insan': 59, 'geri': 59, 'haber': 59, '6': 58, 'yol': 58, 'başbakan': 58, 'buna': 58, 'genç': 57, '2011': 57, 'destek': 57, 'güzel': 57, 'veren': 57, 'altında': 56, 'nedeniyle': 56, 'verdi': 56, 'dünyanın': 56, 'zaten': 56, 'yaptı': 55, 'başkan': 55, 'edilen': 55, 'anda': 55, 'başladı': 55, 'spor': 55, 'ait': 54, 'hava': 54, 'bunlar': 54}\n"
     ]
    }
   ],
   "source": [
    "high_vocabulary={x: count for x, count in vocabulary.most_common() if count >= 5}\n",
    "print(high_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'girdim': 1, 'lokaline': 1, 'müdürler': 1, 'evimiz': 1, 'gülünecek': 1, 'üni': 1, 'lisansuludağ': 1, 'mühendisliği1988': 1, '9999': 1, 'karşıladığını': 1, 'bmnin': 1, 'español': 1, 'français': 1, '中文': 1, 'عربي': 1, 'فارسي': 1, '9998': 1, 'daldı': 1, 'taşınmadan': 1, 'zülkiflin': 1, '9997': 1, 'kesilmesi': 1, 'alâkalarından': 1, 'kalbin': 1, 'takva': 1, 'itikad': 1, 'sağlamlığı': 1, 'zühdü': 1, '9996': 1, 'sığınmayın': 1, 'kalabalığına': 1, 'dolambaçlı': 1, 'örtmecelere': 1, '9995': 1, 'pakerin': 1, 'kapancılar': 1, 'i̇lişkiler': 1, 'risalesinin': 1, '9994': 1, 'sahibidir': 1, 'zincirlikuyuda': 1, 'projesinde': 1, '9993': 1, 'yapışıyorlar': 1, 'sülük': 1, 'satacağız': 1, '9992': 1, 'atmanın': 1, '9991': 1, 'bozulan': 1, 'filyos': 1, 'çaycuma': 1, 'zonguldakın': 1, '9990': 1, 'ambulansta': 1, 'eb': 1, 'iskeleye': 1, 'botla': 1, 'zodyak': 1, '9989': 1, 'kazançoğlu': 1, 'i̇to': 1, 'ayutthaya': 1, '9988': 1, 'gösterilebileceğini': 1, 'incelediği': 1, 'müfredatını': 1, 'tarall': 1, 'sağlanabileceğini': 1, 'entegrasyonun': 1, '9987': 1, 'üzüntülerini': 1, '9986': 1, 'öztaşkın': 1, 'petroli̇ş': 1, '9985': 1, 'gã¶rã¼åÿtã¼ler': 1, 'temsilcileriyle': 1, 'madeninin': 1, 'perlit': 1, 'kiremitin': 1, 'ziyaretã§iler': 1, '9984': 1, 'atiyim': 1, 'mazide': 1, 'kökü': 1, 'harabati': 1, 'harabiyim': 1, 'gökalpe': 1, '9983': 1, 'beğendi': 1, '9982': 1, 'anderson': 1, 'konuşacak': 1, '9981': 1, '9980': 1, 'arındırılması': 1, 'silahlardan': 1, '9979': 1, 'açıklıyor': 1, 'sızdıracağını': 1, 'içeriğini': 1, 'ekibinin': 1, 'önerdiğini': 1, 'başbaşa': 1, 'başbakanının': 1, 'anekdota': 1, 'dennis': 1, '9978': 1, 'yetmeyebilir': 1, 'ödemeye': 1, 'bedelleri': 1, 'nakitleri': 1, '9977': 1, 'vurulmaktadır': 1, 'dağıtımı': 1, '9976': 1, '9975': 1, 'tarzımızla': 1, 'bilme': 1, 'nesnelerden': 1, 'felsefenin': 1, '9974': 1, '9973': 1, 'i̇qlimi': 1, '9972': 1, 'rekabette': 1, 'acımasız': 1, 'kaynaklarla': 1, '9971': 1, 'bitirilen': 1, '9970': 1, 'yaklaşmıştı': 1, 'kerahet': 1, '9969': 1, 'ulaşabilirler': 1, 'yarına': 1, 'sürmeyenler': 1, 'geçmişin': 1, '9968': 1, 'toplantılara': 1, 'ihtişamlı': 1, 'depremi': 1, '9967': 1, 'iddianamede': 1, 'bağı': 1, 'ergenekonla': 1, 'karargâh': 1, '9966': 1, 'sürüyorlar': 1, 'baskalari': 1, 'makamina': 1, 'demokratlik': 1, '9965': 1, 'susmuş': 1, 'hâkimse': 1, '9964': 1, 'sonbaharında': 1, '9963': 1, 'vermektir': 1, 'edeni': 1, '9962': 1, 'ï¿½alï¿½ï¿½maktadï¿½r': 1, 'ï¿½ï¿½zï¿½mleriyle': 1, 'bbssoft': 1, 'ï¿½lsaokyanus': 1, 'baï¿½tan': 1, 'vakfï¿½nï¿½n': 1, 'tï¿½gem': 1, '9961': 1, 'resulullah': 1, 'faziletini': 1, 'dokuzunda': 1, 'zilhiccenin': 1, '9960': 1, 'aldırmazın': 1, '9959': 1, 'çırpınıyorlar': 1, 'vakfa': 1, 'usanmadan': 1, 'bıkmadan': 1, 'başarmışlar': 1, 'denileni': 1, 'başaramazsınız': 1, '9958': 1, 'sıkıntılarını': 1, '9957': 1, 'uygulanabilecek': 1, 'tesisinden': 1, 'zeytinlik': 1, '9956': 1, 'kazandırılır': 1, 'ekonomiye': 1, 'stokçuluğu': 1, 'natural': 1, 'kuyularında': 1, 'fermente': 1, 'depolanabilen': 1, '8er': 1, 'zeytinler': 1, '9955': 1, '2001den': 1, '9954': 1, 'vereceksin': 1, 'oynayacaksan': 1, 'içeceksen': 1, 'rakı': 1, '9953': 1, 'kılığında': 1, 'zeus': 1, '9952': 1, 'kaldırılmıştı': 1, 'şikayetiyle': 1, 'tansiyon': 1, 'zerrin': 1, '9951': 1, 'yumuşacık': 1, 'yenilenmiş': 1, 'cildinizde': 1, 'köpüğü': 1, 'kremli': 1, '9950': 1, 'edilmişlerdir': 1, 'toplumdan': 1, '9949': 1, 'kata': 1, '9948': 1, 'olmalï¿½dï¿½r': 1, 'kalï¿½nlï¿½ï¿½ï¿½nda': 1, 'ï¿½apï¿½': 1, '9947': 1, 'âlimleridir': 1, 'devrin': 1, 'ebussuud': 1, 'cemali': 1, 'zembilli': 1, '9946': 1, 'beyazı': 1, 'zekeriya': 1, '9945': 1, 'tartışmalarsa': 1, '9944': 1, 'nörotoksinler': 1, 'hyaluronidaz': 1, 'antikoagulaz': 1, 'lektinaz': 1, 'zehirinde': 1, '9943': 1, 'korkuyorum': 1, 'azalmasından': 1, 'enerjimin': 1, '9942': 1, 'geldiniz': 1, 'âliniz': 1, 'zatı': 1, '9941': 1, 'oğluna': 1, '9940': 1, '9939': 1, 'kanserli': 1, 'vücudumda': 1, '9938': 1, 'anlatabilirim': 1, 'abartmış': 1, 'atının': 1, 'pegasus': 1, 'binerek': 1, '9937': 1, 'farkındalar': 1, 'brokerlar': 1, 'ayakçı': 1, '9936': 1, '9935': 1, 'tanınırdı': 1, '9934': 1}\n"
     ]
    }
   ],
   "source": [
    "#These values are assumed to have spelling errors\n",
    "low_vocabulary={x: count for x, count in vocabulary.most_common()[::-1] if count <5} #Least common words\n",
    "print(low_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: JPype1 in c:\\users\\barkin\\anaconda3\\lib\\site-packages (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install JPype1\n",
    "from os.path import join\n",
    "from typing import List\n",
    "from jpype import JClass,JString,getDefaultJVMPath,shutdownJVM,startJVM,isJVMStarted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ZEMBEREK_PATH = 'C:/Users/barkin/Zemberek-Python-Examples-master/bin/zemberek-full.jar'\n",
    "\n",
    "#Or you can not re-run the cell if it has error\n",
    "def init_jvm():\n",
    "    if isJVMStarted():\n",
    "        return \"JVM is already started\"\n",
    "    startJVM(getDefaultJVMPath(),\n",
    "        '-ea',\n",
    "        f'-Djava.class.path={ZEMBEREK_PATH}',\n",
    "        convertStrings=False)\n",
    "\n",
    "init_jvm()\n",
    "\n",
    "TurkishMorphology:JClass=JClass('zemberek.morphology.TurkishMorphology')\n",
    "TurkishSpellChecker:JClass=JClass('zemberek.normalization.TurkishSpellChecker')\n",
    "\n",
    "morphology: TurkishMorphology = TurkishMorphology.createWithDefaults()\n",
    "spell_checker: TurkishSpellChecker = TurkishSpellChecker(morphology)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-frequency words  Similar high-frequency words \n",
      "üni                  ani                           \n",
      "bmnin                binin                         \n",
      "français             François                      \n",
      "zülkiflin            Zelkif'lin                    \n",
      "alâkalarından        alakalarından                 \n",
      "itikad               Utikad                        \n",
      "örtmecelere          örtmecilere                   \n",
      "pakerin              paketin                       \n",
      "i̇lişkiler           ilişkiler                     \n",
      "zincirlikuyuda       Zincirlikuyu'da               \n",
      "filyos               Filyos                        \n",
      "çaycuma              Çaycuma                       \n",
      "zonguldakın          Zonguldak'ın                  \n",
      "eb                   en                            \n",
      "kazançoğlu           Kazançoğlu                    \n",
      "i̇to                 ito                           \n",
      "tarall               taralı                        \n",
      "öztaşkın             Öztaş'çın                     \n",
      "kiremitin            kiremitsin                    \n",
      "gökalpe              Gökalp                        \n",
      "anderson             Anderson                      \n",
      "dennis               Denis                         \n",
      "ergenekonla          Ergenekon'da                  \n",
      "karargâh             karargah                      \n",
      "baskalari            Bask'alar                     \n",
      "makamina             makamına                      \n",
      "demokratlik          demokratik                    \n",
      "hâkimse              hekimse                       \n",
      "resulullah           Resulullah                    \n",
      "natural              Natural                       \n",
      "8er                  her                           \n",
      "zeus                 Zeus                          \n",
      "âlimleridir          alimleridir                   \n",
      "ebussuud             Ebussuud'u                    \n",
      "zekeriya             Zekeriya                      \n",
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f75eda37ba30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Low-frequency words  Similar high-frequency words \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlow_vocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mspell_checker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggestForWord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mspell_checker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mspellCheckedWord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspell_checker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggestForWord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Low-frequency words  Similar high-frequency words \")\n",
    "for i,word in enumerate(low_vocabulary):\n",
    "    if spell_checker.suggestForWord(JString(word)):\n",
    "        if not spell_checker.check(JString(word)):\n",
    "            spellCheckedWord = str(spell_checker.suggestForWord(JString(word))[0])\n",
    "            print(f\"{word:{20}} {spellCheckedWord:{30}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
