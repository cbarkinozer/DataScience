{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\barkin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "f= open('the_hunger_games.txt','r',encoding='utf8')\n",
    "text=f.read()\n",
    "f.close()\n",
    "\n",
    "#Cleaning the text from punctuations\n",
    "import string\n",
    "clean_text = text.translate(str.maketrans('','', string.punctuation)).lower()\n",
    "\n",
    "#Downloading the Turkish stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "my_stopwords=set(stopwords.words('turkish'))\n",
    "\n",
    "#Tokenization\n",
    "words =nltk.word_tokenize(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a frequency table to keep the score of each word\n",
    "#Also cleaning stop words.\n",
    "\n",
    "word_count=0\n",
    "freqTable = dict()\n",
    "for word in words:\n",
    "    word_count=word_count+1\n",
    "    word = word.lower()\n",
    "    if word in stopWords:\n",
    "        continue\n",
    "    if word in freqTable:\n",
    "        freqTable[word] += 1\n",
    "    else:\n",
    "        freqTable[word] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loading: % 1.1734693877551021 "
     ]
    }
   ],
   "source": [
    "# Creating a dictionary to keep the score\n",
    "# of each sentence\n",
    "import sys\n",
    "sentences = sent_tokenize(text)\n",
    "sentenceValue = dict()\n",
    "counter=0   \n",
    "for sentence in sentences:\n",
    "    for word, freq in freqTable.items():\n",
    "        if word in sentence.lower():\n",
    "            counter=counter+1\n",
    "            if(counter%10==0):\n",
    "                print(\"\\r Loading: %\",counter/word_count,end=\" \")#Logging for large files\n",
    "            if sentence in sentenceValue:\n",
    "                sentenceValue[sentence] += freq\n",
    "            else:\n",
    "                sentenceValue[sentence] = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumValues = 0\n",
    "for sentence in sentenceValue:\n",
    "    sumValues += sentenceValue[sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 lines of The Hunger Games Book's summary by our text summarizer \n",
      "\n",
      "ORIGINAL TEXT\n",
      "\n",
      "Uyandığımda yatağın diğer tarafı soğuktu. Parmaklarım uzandı, Prim'in sıcaklığını aradı ama sadece şiltenin kaba kanvas örtüsünü buldu. Kötü rüyalar görmüş ve annemizin yanına tırmanmış olmalı. Elbette, öyle yaptı. Bugün hasat günü. Kendimi bir dirseğimin desteğiyle dikeliyorum. Yatak odasında onları görmeye yetecek kadar ışık var. Küçük kız kardeşim Prim, yanaklarını birbirine bastırmış, annemin vücudunda kozalanmış bir şekilde yanına kıvrılmış. Annem uykuda daha genç görünüyor, biraz yıpranmış ama o kadar da yıpranmış değil. Prim'in yüzü bir yağmur damlası kadar taze, adını aldığı çuha çiçeği kadar güzel. Annem de bir zamanlar çok güzeldi. Ya da bana öyle diyorlar. Prim'in dizlerine oturup onu koruyan ise , dünyanın en çirkin kedisidir. Burnu ezik, bir kulağın yarısı eksik, gözleri çürük kabak renginde. Prim, çamurumsu sarı kürkünün parlak bir çiçeğe uyduğuda ısrar ederek ona Buttercup adını verdi. Benden nefret ediyor. Ya da en azından bana güvenmiyor. Yıllar önce olmasına rağmen, Prim onu eve getirdiğinde onu nasıl bir kovada boğmaya çalıştığımı hâlâ hatırlıyor. Sıska kedi yavrusu, karnı solucanlarla şişmiş, pirelerle sürünüyor. İhtiyacım olan son şey, besleyecek başka bir ağızdı. Ama Prim çok yalvardı, hatta ağladı, kalmasına izin vermek zorunda kaldım. Hayatta kaldı. Annem haşaratlardan kurtuldu ve o doğuştan fare avcısı. Ara sıra fareyi bile yakalar.\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "SUMMARY OF THE TEXT\n",
      "\n",
      " Parmaklarım uzandı, Prim'in sıcaklığını aradı ama sadece şiltenin kaba kanvas örtüsünü buldu. Küçük kız kardeşim Prim, yanaklarını birbirine bastırmış, annemin vücudunda kozalanmış bir şekilde yanına kıvrılmış. Annem uykuda daha genç görünüyor, biraz yıpranmış ama o kadar da yıpranmış değil. Prim'in yüzü bir yağmur damlası kadar taze, adını aldığı çuha çiçeği kadar güzel. Burnu ezik, bir kulağın yarısı eksik, gözleri çürük kabak renginde. Prim, çamurumsu sarı kürkünün parlak bir çiçeğe uyduğuda ısrar ederek ona Buttercup adını verdi. Yıllar önce olmasına rağmen, Prim onu eve getirdiğinde onu nasıl bir kovada boğmaya çalıştığımı hâlâ hatırlıyor. Ama Prim çok yalvardı, hatta ağladı, kalmasına izin vermek zorunda kaldım.\n"
     ]
    }
   ],
   "source": [
    "# Average value of a sentence from the original text  \n",
    "average = int(sumValues / len(sentenceValue))\n",
    "# Storing sentences into our summary.\n",
    "summary = ''\n",
    "for sentence in sentences:\n",
    "    if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)):\n",
    "        summary += \" \" + sentence\n",
    "print(\"\\nFirst 10 lines of The Hunger Games Book's summary by our text summarizer \\n\")\n",
    "print(\"ORIGINAL TEXT\\n\")\n",
    "print(text)\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"SUMMARY OF THE TEXT\\n\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**253 words summarized to 150 words which makes 59% length of the original text.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
